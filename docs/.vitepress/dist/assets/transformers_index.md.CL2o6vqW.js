import{_ as e,c as t,a2 as a,G as n,w as p,B as l,o,a as r}from"./chunks/framework.H8_ecXae.js";const y=JSON.parse('{"title":"Transformers Quickstart","description":"","frontmatter":{},"headers":[],"relativePath":"transformers/index.md","filePath":"transformers/index.md"}'),h={name:"transformers/index.md"};function d(k,s,c,E,g,u){const i=l("center");return o(),t("div",null,[s[1]||(s[1]=a('<h1 id="transformers-quickstart" tabindex="-1">Transformers Quickstart <a class="header-anchor" href="#transformers-quickstart" aria-label="Permalink to &quot;Transformers Quickstart&quot;">​</a></h1><p>Essa é uma traduçao (com pequenos ajustes) do material <a href="https://huggingface.co/docs/transformers/quicktour" target="_blank" rel="noreferrer">transformers quicktour</a> do Hugging Face.</p><h2 id="introducao" tabindex="-1">Introdução <a class="header-anchor" href="#introducao" aria-label="Permalink to &quot;Introdução&quot;">​</a></h2><p>Este post mostrará como usar o <code>pipeline()</code> para inferência, como carregar um modelo pré-treinado, um pré-processador e treinar um modelo com <strong>PyTorch</strong>.</p><p>Antes de começar, certifique-se de ter todas as bibliotecas necessárias instaladas:</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> transformers</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> datasets</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> evaluate</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> accelerate</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> torch</span></span></code></pre></div><p>O <code>pipeline()</code> é a maneira mais fácil e rápida de usar um modelo pré-treinado para inferência. Você pode usar o <code>pipeline()</code> pronto para uso para muitas Tarefas (Tabela 1) em diferentes modalidades, algumas das quais são mostradas na tabela abaixo:</p>',7)),n(i,null,{default:p(()=>s[0]||(s[0]=[r("Tabela 1 - Tarefas possíveis com o pipeline do Transformers.")])),_:1}),s[2]||(s[2]=a(`<table tabindex="0"><thead><tr><th>Descriçao da Tarefa</th><th>Identificador do Pipeline</th></tr></thead><tbody><tr><td>Classificação de texto</td><td>pipeline(task=“sentiment-analysis”)</td></tr><tr><td>Geração de Texto</td><td>pipeline(task=“text-generation”)</td></tr><tr><td>reconhecimento automático de fala</td><td>pipeline(task=“automatic-speech-recognition”)</td></tr></tbody></table><h2 id="exemplo-analise-de-sentimento" tabindex="-1">Exemplo análise de sentimento <a class="header-anchor" href="#exemplo-analise-de-sentimento" aria-label="Permalink to &quot;Exemplo análise de sentimento&quot;">​</a></h2><p>Comece criando uma instância de <code>pipeline()</code> e especificando uma tarefa para a qual você deseja usá-lo. O <code>pipeline()</code> baixa e armazena em cache um modelo pré-treinado padrão e um tokenizador para análise de sentimento. Agora você pode usar o classificador no seu texto de destino. Neste guia, você usará o <code>pipeline()</code> para análise de sentimentos como um exemplo:</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> transformers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pipeline</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">classifier </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pipeline(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;sentiment-analysis&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">classifier(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;We are very happy to show you the Transformers library.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>[{&#39;label&#39;: &#39;POSITIVE&#39;, &#39;score&#39;: 0.9997795224189758}]</span></span></code></pre></div><p>Se você tiver mais de uma entrada, passe suas entradas como uma lista para o <code>pipeline()</code> para retornar uma lista de dicionários:</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> transformers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pipeline</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">classifier </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pipeline(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;sentiment-analysis&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">results </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> classifier([</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;We are very happy to show you the Transformers library.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;We hope you don&#39;t hate it.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> result </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> results:</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;label: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">result[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;label&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">, with score: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{round</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(result[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;score&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>label: POSITIVE, with score: 0.9998</span></span>
<span class="line"><span>label: NEGATIVE, with score: 0.5309</span></span></code></pre></div><h2 id="exemplo-reconhecimento-automatico-de-fala" tabindex="-1">Exemplo reconhecimento automático de fala <a class="header-anchor" href="#exemplo-reconhecimento-automatico-de-fala" aria-label="Permalink to &quot;Exemplo reconhecimento automático de fala&quot;">​</a></h2><p>O <code>pipeline()</code> também pode iterar um conjunto de dados inteiro para qualquer tarefa que você desejar. Para este exemplo, vamos escolher o pipeline <strong>reconhecimento automático de fala</strong> utilizando o modelo <a href="https://huggingface.co/facebook/wav2vec2-base-960h" target="_blank" rel="noreferrer">facebook/wav2vec2-base-960h</a></p><p>Instale a dependência:</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> librosa</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> soundfile</span></span></code></pre></div><p>Carregue um conjunto de dados de áudio que você gostaria de iterar. Por exemplo, carregue o conjunto de dados <a href="https://huggingface.co/datasets/PolyAI/minds14" target="_blank" rel="noreferrer">MInDS-14</a></p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> transformers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pipeline</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> datasets </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> load_dataset, Audio</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">speech_recognizer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pipeline(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;automatic-speech-recognition&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;facebook/wav2vec2-base-960h&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># carregando o conjunto de dados MInDS-14</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">dataset </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> load_dataset(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;PolyAI/minds14&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">name</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;en-US&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">split</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;train&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Você precisa ter certeza de que a taxa de amostragem do conjunto de dados </span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># corresponde à taxa de amostragem em que facebook/wav2vec2-base-960h foi treinado:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">dataset </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dataset.cast_column(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;audio&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, Audio(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">sampling_rate</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">speech_recognizer.feature_extractor.sampling_rate))</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Os arquivos de áudio são automaticamente carregados e reamostrados ao chamar a coluna &quot;audio&quot;.</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Extraia os arrays de forma de onda bruta (raw waveform) das primeiras 4 amostras e passe-os como uma lista para o pipeline:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">result </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> speech_recognizer(dataset[:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;audio&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">([d[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;text&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> d </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> result])</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>[&#39;I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT&#39;, </span></span>
<span class="line"><span>&quot;FONDERING HOW I&#39;D SET UP A JOIN TO HELL T WITH MY WIFE AND WHERE THE AP MIGHT BE&quot;, </span></span>
<span class="line"><span>... </span></span>
<span class="line"><span>&#39;HOW DO I FURN A JOINA COUT&#39;]</span></span></code></pre></div><p>Mais sobre datasets pode ser encontrado em <a href="https://huggingface.co/docs/datasets/quickstart" target="_blank" rel="noreferrer">Hugging Face Dataset Quick Tour</a></p><p>Para conjuntos de dados maiores onde as entradas são grandes (como fala ou visão), você desejará passar um gerador em vez de uma lista para carregar todas as entradas na memória. Dê uma olhada na referência da <a href="https://huggingface.co/docs/transformers/main_classes/pipelines" target="_blank" rel="noreferrer">API do pipeline</a> para obter mais informações.</p><h2 id="use-outro-modelo-e-tokenizer-no-pipeline" tabindex="-1">Use outro modelo e tokenizer no pipeline <a class="header-anchor" href="#use-outro-modelo-e-tokenizer-no-pipeline" aria-label="Permalink to &quot;Use outro modelo e tokenizer no pipeline&quot;">​</a></h2><p>O <code>pipeline()</code> pode acomodar qualquer modelo (model) do <a href="https://huggingface.co/models" target="_blank" rel="noreferrer">Hub</a>, facilitando a adaptação do <code>pipeline()</code> para outros casos de uso. Por exemplo, se você quiser um modelo capaz de lidar com texto em francês, encontre o nome do modelo realizando uma busca no <a href="https://huggingface.co/models" target="_blank" rel="noreferrer">Hub</a>. Faça o filtro por task=&quot;Text classification&quot;, Language=&quot;fr&quot; e sorte=&quot;liked&quot; para encontrar um modelo apropriado. O resultado do <a href="https://huggingface.co/models?pipeline_tag=text-classification&amp;language=fr&amp;sort=likes" target="_blank" rel="noreferrer">filtro anterior</a> retorna o modelo BERT <a href="https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment" target="_blank" rel="noreferrer">bert-base-multilingual-uncased-sentiment</a> ajustado (finetuned) para <strong>análise de sentimento</strong> que você pode usar para textos em francês. Este modelo ajustado retorna 1 a 5 estrelas e foi treinado com reviews de produtos. Segue um exemplo de uso do modelo encontrado (BERT) para análise de sentimento de um texto em inglês.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> transformers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pipeline</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">classifier </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pipeline(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;sentiment-analysis&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;nlptown/bert-base-multilingual-uncased-sentiment&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(classifier(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;We are very happy to show you the Transformers library.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>[{&#39;label&#39;: &#39;5 stars&#39;, &#39;score&#39;: 0.7495927214622498}]</span></span></code></pre></div><p>É possível informar além do modelo para o <code>pipeline</code> um tokenizer diferente. Vamos identificar qual o tokenizer associado a determinado modelo, e informá-lo no parâmetro do <code>pipeline</code></p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> transformers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> AutoTokenizer, AutoModelForSequenceClassification</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> AutoModelForSequenceClassification.from_pretrained(model_name)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tokenizer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> AutoTokenizer.from_pretrained(model_name)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">classifier </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pipeline(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;sentiment-analysis&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">tokenizer</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tokenizer)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(classifier(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Nous sommes très heureux de vous présenter la bibliothèque 🤗 Transformers.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>[{&#39;label&#39;: &#39;5 stars&#39;, &#39;score&#39;: 0.7272651791572571}]</span></span></code></pre></div><p>Se não conseguir encontrar um modelo para seu caso de uso, você precisará ajustar um modelo pré-treinado em seus dados. Dê uma olhada no <a href="https://huggingface.co/docs/transformers/training" target="_blank" rel="noreferrer">tutorial de ajuste fino</a> para saber como. Por fim, depois de ajustar seu modelo pré-treinado, considere <a href="https://huggingface.co/docs/transformers/model_sharing" target="_blank" rel="noreferrer">compartilhar o modelo</a> com a comunidade no Hub para democratizar o aprendizado de máquina para todos!</p>`,25))])}const F=e(h,[["render",d]]);export{y as __pageData,F as default};
