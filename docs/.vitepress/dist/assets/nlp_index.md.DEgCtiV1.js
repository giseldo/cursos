import{_ as e,c as o,a2 as s,o as t}from"./chunks/framework.H8_ecXae.js";const r="/cursos/assets/ia.DmjlkJZL.png",g=JSON.parse('{"title":"PLN","description":"","frontmatter":{"draft":true},"headers":[],"relativePath":"nlp/index.md","filePath":"nlp/index.md"}'),i={name:"nlp/index.md"};function n(d,a,p,c,l,m){return t(),o("div",null,a[0]||(a[0]=[s('<h1 id="pln" tabindex="-1">PLN <a class="header-anchor" href="#pln" aria-label="Permalink to &quot;PLN&quot;">​</a></h1><h2 id="sobre" tabindex="-1">Sobre <a class="header-anchor" href="#sobre" aria-label="Permalink to &quot;Sobre&quot;">​</a></h2><p>Esse material é uma tradução em português brasileiro desse <a href="https://medium.com/@vipra_singh/llm-architectures-explained-nlp-fundamentals-part-1-de5bf75e553a" target="_blank" rel="noreferrer">artigo no medium</a></p><p><a href="https://medium.com/@vipra_singh" target="_blank" rel="noreferrer">Mais artigos da autora</a> com outros materiais explicativos.</p><h2 id="o-que-e-pln" tabindex="-1">O que é PLN? <a class="header-anchor" href="#o-que-e-pln" aria-label="Permalink to &quot;O que é PLN?&quot;">​</a></h2><p>Processamento de linguagem natural (PLN) é a disciplina de construção de máquinas que podem manipular a linguagem humana — ou dados que se assemelham à linguagem humana — da maneira como são escritos, falados e organizados.</p><p><img src="'+r+`" alt=""></p><p>A PNL é amplamente dividida em duas áreas sobrepostas:</p><p>Natural Language Understanding (NLU), que lida com a interpretação do significado por trás do texto, e</p><p>Natural Language Generation (NLG), que se concentra na produção de texto que imita a escrita humana. Embora seja diferente do reconhecimento de fala — que converte a linguagem falada em texto — a PNL geralmente trabalha em conjunto com ele.</p><h2 id="aplicacoes-da-pnl" tabindex="-1">Aplicações da PNL <a class="header-anchor" href="#aplicacoes-da-pnl" aria-label="Permalink to &quot;Aplicações da PNL&quot;">​</a></h2><p>A PNL é usada para várias tarefas relacionadas à linguagem, incluindo responder perguntas, classificar texto de várias maneiras e conversar com usuários.</p><p>Aqui estão algumas das tarefas que a PNL pode resolver:</p><p><strong>Análise de Sentimentos</strong>: Isso envolve determinar o tom emocional do texto. A entrada é tipicamente um pedaço de texto, e a saída é uma distribuição de probabilidade indicando se o sentimento é positivo, negativo ou neutro. As técnicas variam de métodos tradicionais como TF-IDF e n-grams a modelos de aprendizado profundo como BERT e LSTM.</p><p><strong>Classificação de Toxicidade</strong>: Uma forma especializada de análise de sentimentos, a classificação de toxicidade identifica a intenção hostil e a categoriza em tipos específicos, como ameaças ou insultos. Isso é usado para moderar conteúdo online, garantindo espaços digitais mais seguros.</p><p><strong>Tradução de Máquina</strong>: Isso automatiza a tradução de texto de um idioma para outro. Modelos avançados como o GPT-4 da OpenAI e os modelos baseados em Transformer do Google estão liderando o caminho para tornar as traduções mais precisas e contextualmente conscientes.</p><p><strong>Reconhecimento de Entidade Nomeada (NER)</strong>: Os modelos NER extraem e classificam entidades como nomes, organizações e locais do texto. Esses modelos são essenciais para resumir notícias e combater a desinformação.</p><p><strong>Detecção de spam</strong>: modelos de detecção de spam classificam e-mails como spam ou não, ajudando serviços de e-mail como o Gmail a filtrar mensagens indesejadas. Esses modelos geralmente dependem de técnicas como regressão logística, Naive Bayes ou aprendizado profundo (<em>deep learning</em>).</p><p><strong>Correção de erros gramaticais</strong>: modelos que corrigem erros gramaticais são amplamente usados ​​em ferramentas como Grammarly. Eles tratam a correção gramatical como um problema de sequência para sequência, onde a entrada é uma frase incorreta e a saída é uma versão corrigida.</p><p><strong>Modelagem de tópicos</strong>: a modelagem de tópicos identifica tópicos abstratos dentro de um corpus de documentos. Técnicas como Alocação de Dirichlet Latente (LDA) são comumente usadas em análise de documentos legais e sistemas de recomendação de conteúdo.</p><p><strong>Geração de texto (NLG)</strong>: modelos NLG geram texto semelhante ao humano, útil para aplicativos que variam de chatbots à preenchimento automático. Preenchimento automático são sistemas que preveem a próxima palavra em uma sequência, usados ​​em aplicativos como mecanismos de busca e aplicativos de mensagens. Chatbots simulam conversas humanas.</p><p><strong>Recuperação de informações</strong>: envolve encontrar documentos relevantes para uma consulta, crucial para mecanismos de busca e sistemas de recomendação. Os modelos mais recentes do Google usam abordagens multimodais para lidar com dados de texto, imagem e vídeo simultaneamente.</p><p><strong>Resumo(Summarization)</strong> é a tarefa de encurtar o texto para destacar as informações mais relevantes. O resumo é dividido em duas classes de métodos:</p><ul><li><p>O resumo extrativo foca em extrair as frases mais importantes de um texto longo e combiná-las para formar um resumo. Normalmente, o resumo extrativo pontua cada frase em um texto de entrada e então seleciona várias frases para formar o resumo.</p></li><li><p>O resumo abstrativo produz um resumo por paráfrase. Isso é semelhante a escrever o resumo que inclui palavras e frases que não estão presentes no texto original. O resumo abstrativo é geralmente modelado como uma tarefa de sequência para sequência (sequence-to-sequence), onde a entrada é um texto longo e a saída é um resumo.</p></li></ul><p><strong>Resposta a perguntas (QA)</strong> lida com responder perguntas feitas por humanos em uma linguagem natural. Um dos exemplos mais notáveis ​​de resposta a perguntas foi Watson, que em 2011 jogou o game show de televisão Jeopardy contra campeões humanos e venceu por margens substanciais. Geralmente, as tarefas de resposta a perguntas vêm em dois tipos:</p><ul><li><p>Múltipla escolha: O problema de pergunta de múltipla escolha é composto de uma pergunta e um conjunto de respostas possíveis. A tarefa de aprendizagem é escolher a resposta correta.</p></li><li><p>Domínio aberto: Na resposta a perguntas de domínio aberto, o modelo fornece respostas a perguntas em linguagem natural sem nenhuma opção fornecida, geralmente consultando um grande número de textos.</p></li></ul><h2 id="termos-da-pln" tabindex="-1">Termos da PLN <a class="header-anchor" href="#termos-da-pln" aria-label="Permalink to &quot;Termos da PLN&quot;">​</a></h2><h3 id="documento" tabindex="-1">Documento <a class="header-anchor" href="#documento" aria-label="Permalink to &quot;Documento&quot;">​</a></h3><p>Um documento é um único pedaço de texto, que pode ser qualquer coisa, desde uma única frase até um livro inteiro. É a unidade básica de texto que os modelos de PNL processam. Os documentos podem ser de natureza diversa, como e-mails, páginas da web, artigos ou tweets.</p><p>Exemplo:</p><ul><li>Um único artigo de notícias de um jornal.</li><li>Um tweet: &quot;Acabei de assistir a um filme incrível!&quot;</li><li>Um e-mail: &quot;Caro John, espero que este e-mail o encontre bem...&quot;</li></ul><h3 id="corpus-corpora" tabindex="-1">Corpus (Corpora) <a class="header-anchor" href="#corpus-corpora" aria-label="Permalink to &quot;Corpus (Corpora)&quot;">​</a></h3><p>Um corpus (plural: corpora) é uma grande coleção de documentos. Ele serve como o conjunto de dados no qual os modelos de PNL são treinados e avaliados. Um corpus normalmente contém documentos relacionados por tópico, idioma ou gênero e é usado para analisar padrões linguísticos e construir modelos estatísticos.</p><p>Exemplo:</p><ul><li>Uma coleção de todos os artigos de um jornal específico ao longo de um ano.</li><li>Um conjunto de dados de avaliações de clientes de um site de comércio eletrônico.</li><li>O Corpus de Gutenberg: Uma coleção de textos literários do Projeto Gutenberg.</li></ul><h3 id="recurso-feature" tabindex="-1">Recurso (Feature) <a class="header-anchor" href="#recurso-feature" aria-label="Permalink to &quot;Recurso (Feature)&quot;">​</a></h3><p>Um recurso (feature) é uma propriedade ou característica mensurável do texto que é usada em modelos de aprendizado de máquina. Os recursos (features) são extraídos de documentos e podem representar vários aspectos do texto, como a presença de palavras específicas, o comprimento das frases ou a ocorrência de padrões específicos.</p><p>Exemplo:</p><h4 id="bag-of-words-bow" tabindex="-1">Bag-of-Words (BoW): <a class="header-anchor" href="#bag-of-words-bow" aria-label="Permalink to &quot;Bag-of-Words (BoW):&quot;">​</a></h4><p>Cada palavra no vocabulário é um recurso (feature), e o valor é a contagem da palavra no documento.</p><p>Documento:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>&quot;Eu amo PNL.&quot;</span></span></code></pre></div><p>Recursos/features:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>[ &quot;Eu&quot;: 1, &quot;amo&quot;: 1, &quot;PNL&quot;: 1 ]</span></span></code></pre></div><h4 id="frequencia-de-termo-frequencia-inversa-do-documento-tf-idf" tabindex="-1">Frequência de termo-frequência inversa do documento (TF-IDF): <a class="header-anchor" href="#frequencia-de-termo-frequencia-inversa-do-documento-tf-idf" aria-label="Permalink to &quot;Frequência de termo-frequência inversa do documento (TF-IDF):&quot;">​</a></h4><p>Uma medida estatística usada para avaliar a importância de uma palavra em um documento em relação a um corpus.</p><p>Documento:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>&quot;Aprendizado de máquina é divertido.&quot;</span></span></code></pre></div><p>Recursos/features (pontuações TF-IDF):</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>[ &quot;máquina&quot;: 0.5, &quot;Aprendizado&quot;: 0.5, &quot;é&quot;: 0.1, &quot;divertido&quot;: 0.7 ]</span></span></code></pre></div><h4 id="tags-de-classe-de-fala-part-of-speech-pos" tabindex="-1">Tags de Classe de Fala (Part of Speech/POS): <a class="header-anchor" href="#tags-de-classe-de-fala-part-of-speech-pos" aria-label="Permalink to &quot;Tags de Classe de Fala (Part of Speech/POS):&quot;">​</a></h4><p>Características que indicam a categoria gramatical de cada palavra (por exemplo, substantivo, verbo, adjetivo).</p><p>Documento:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>“A rápida raposa marrom salta.”</span></span></code></pre></div><p>Características:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>[A”: “DET”, “rápida: “ADJ”, “marrom”: “ADJ”, “fox”: “raposa”, “jumps”: “VERB”]</span></span></code></pre></div><p>Por exemplo, vamos considerar os 2 documentos mostrados abaixo:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Dog hates a cat. </span></span>
<span class="line"><span>It loves to go out and play. Cat loves to play with a ball.</span></span></code></pre></div><p>Podemos construir um corpus a partir dos 2 documentos acima apenas combinando-os.</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Corpus = “Dog hates a cat. It loves to go out and play. Cat loves to play with a ball.”</span></span></code></pre></div><p>E as características serão todas palavras únicas:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>features: [‘and’, ‘ball’, ‘cat’, ‘dog’, ‘go’, ‘hates’, ‘it’, ‘loves’, ‘out’, ‘play’, ‘to’, ‘with’]</span></span></code></pre></div><p>Chamaremos isso de vetor de características/recursos/feature.</p><h2 id="pre-processamento-de-dados" tabindex="-1">Pré-processamento de dados <a class="header-anchor" href="#pre-processamento-de-dados" aria-label="Permalink to &quot;Pré-processamento de dados&quot;">​</a></h2><p>Antes que um modelo processe o texto para uma tarefa específica, o texto geralmente precisa ser pré-processado para melhorar o desempenho do modelo ou para transformar palavras e caracteres em um formato que o modelo possa entender. Várias técnicas podem ser usadas neste pré-processamento de dados:</p><h3 id="tokenizacao" tabindex="-1">Tokenização <a class="header-anchor" href="#tokenizacao" aria-label="Permalink to &quot;Tokenização&quot;">​</a></h3><p>O processo de dividir o texto em unidades menores chamadas tokens, que podem ser palavras, subpalavras ou caracteres.</p><p>Tipos:</p><p><strong>Tokenização de palavras</strong>: dividir o texto em palavras individuais.</p><p>Exemplo:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>&quot;I study Machine Learning on GeeksforGeeks.&quot;</span></span></code></pre></div><p>será tokenizada por palavra como</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>[‘I’, ‘study’, ‘Machine’, ‘Learning’, ‘on’, ‘GeeksforGeeks’, ‘.’]</span></span></code></pre></div><p><strong>Tokenização de frase</strong>: Dividir texto em frases individuais.</p><p>Exemplo:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>“Eu estudo Machine Learning no GeeksforGeeks. Atualmente, estou estudando PNL”</span></span></code></pre></div><p>será tokenizada por frase como</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>[‘Eu estudo Machine Learning no GeeksforGeeks.’, ‘Atualmente, estou estudando PNL.’]</span></span></code></pre></div><p><strong>Tokenização de subpalavra</strong>: Dividir palavras em unidades menores, como prefixos, sufixos ou caracteres individuais.</p><p>Importância: A tokenização é o primeiro passo em muitos pipelines de PNL e afeta os estágios de processamento subsequentes.</p>`,80)]))}const h=e(i,[["render",n]]);export{g as __pageData,h as default};
