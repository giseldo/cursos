import{_ as e,c as t,a2 as a,G as n,w as p,B as l,o,a as r}from"./chunks/framework.H8_ecXae.js";const y=JSON.parse('{"title":"Transformers Quickstart","description":"","frontmatter":{},"headers":[],"relativePath":"transformers/index.md","filePath":"transformers/index.md"}'),h={name:"transformers/index.md"};function d(k,s,c,E,g,u){const i=l("center");return o(),t("div",null,[s[1]||(s[1]=a('<h1 id="transformers-quickstart" tabindex="-1">Transformers Quickstart <a class="header-anchor" href="#transformers-quickstart" aria-label="Permalink to &quot;Transformers Quickstart&quot;">‚Äã</a></h1><p>Essa √© uma tradu√ßao (com pequenos ajustes) do material <a href="https://huggingface.co/docs/transformers/quicktour" target="_blank" rel="noreferrer">transformers quicktour</a> do Hugging Face.</p><h2 id="introducao" tabindex="-1">Introdu√ß√£o <a class="header-anchor" href="#introducao" aria-label="Permalink to &quot;Introdu√ß√£o&quot;">‚Äã</a></h2><p>Este post mostrar√° como usar o <code>pipeline()</code> para infer√™ncia, como carregar um modelo pr√©-treinado, um pr√©-processador e treinar um modelo com <strong>PyTorch</strong>.</p><p>Antes de come√ßar, certifique-se de ter todas as bibliotecas necess√°rias instaladas:</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> transformers</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> datasets</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> evaluate</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> accelerate</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> torch</span></span></code></pre></div><p>O <code>pipeline()</code> √© a maneira mais f√°cil e r√°pida de usar um modelo pr√©-treinado para infer√™ncia. Voc√™ pode usar o <code>pipeline()</code> pronto para uso para muitas Tarefas (Tabela 1) em diferentes modalidades, algumas das quais s√£o mostradas na tabela abaixo:</p>',7)),n(i,null,{default:p(()=>s[0]||(s[0]=[r("Tabela 1 - Tarefas poss√≠veis com o pipeline do Transformers.")])),_:1}),s[2]||(s[2]=a(`<table tabindex="0"><thead><tr><th>Descri√ßao da Tarefa</th><th>Identificador do Pipeline</th></tr></thead><tbody><tr><td>Classifica√ß√£o de texto</td><td>pipeline(task=‚Äúsentiment-analysis‚Äù)</td></tr><tr><td>Gera√ß√£o de Texto</td><td>pipeline(task=‚Äútext-generation‚Äù)</td></tr><tr><td>reconhecimento autom√°tico de fala</td><td>pipeline(task=‚Äúautomatic-speech-recognition‚Äù)</td></tr></tbody></table><h2 id="exemplo-analise-de-sentimento" tabindex="-1">Exemplo an√°lise de sentimento <a class="header-anchor" href="#exemplo-analise-de-sentimento" aria-label="Permalink to &quot;Exemplo an√°lise de sentimento&quot;">‚Äã</a></h2><p>Comece criando uma inst√¢ncia de <code>pipeline()</code> e especificando uma tarefa para a qual voc√™ deseja us√°-lo. O <code>pipeline()</code> baixa e armazena em cache um modelo pr√©-treinado padr√£o e um tokenizador para an√°lise de sentimento. Agora voc√™ pode usar o classificador no seu texto de destino. Neste guia, voc√™ usar√° o <code>pipeline()</code> para an√°lise de sentimentos como um exemplo:</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> transformers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pipeline</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">classifier </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pipeline(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;sentiment-analysis&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">classifier(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;We are very happy to show you the Transformers library.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>[{&#39;label&#39;: &#39;POSITIVE&#39;, &#39;score&#39;: 0.9997795224189758}]</span></span></code></pre></div><p>Se voc√™ tiver mais de uma entrada, passe suas entradas como uma lista para o <code>pipeline()</code> para retornar uma lista de dicion√°rios:</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> transformers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pipeline</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">classifier </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pipeline(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;sentiment-analysis&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">results </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> classifier([</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;We are very happy to show you the Transformers library.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;We hope you don&#39;t hate it.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> result </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> results:</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;label: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">result[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;label&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">, with score: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{round</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(result[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;score&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>label: POSITIVE, with score: 0.9998</span></span>
<span class="line"><span>label: NEGATIVE, with score: 0.5309</span></span></code></pre></div><h2 id="exemplo-reconhecimento-automatico-de-fala" tabindex="-1">Exemplo reconhecimento autom√°tico de fala <a class="header-anchor" href="#exemplo-reconhecimento-automatico-de-fala" aria-label="Permalink to &quot;Exemplo reconhecimento autom√°tico de fala&quot;">‚Äã</a></h2><p>O <code>pipeline()</code> tamb√©m pode iterar um conjunto de dados inteiro para qualquer tarefa que voc√™ desejar. Para este exemplo, vamos escolher o pipeline <strong>reconhecimento autom√°tico de fala</strong> utilizando o modelo <a href="https://huggingface.co/facebook/wav2vec2-base-960h" target="_blank" rel="noreferrer">facebook/wav2vec2-base-960h</a></p><p>Instale a depend√™ncia:</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> librosa</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> soundfile</span></span></code></pre></div><p>Carregue um conjunto de dados de √°udio que voc√™ gostaria de iterar. Por exemplo, carregue o conjunto de dados <a href="https://huggingface.co/datasets/PolyAI/minds14" target="_blank" rel="noreferrer">MInDS-14</a></p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> transformers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pipeline</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> datasets </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> load_dataset, Audio</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">speech_recognizer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pipeline(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;automatic-speech-recognition&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;facebook/wav2vec2-base-960h&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># carregando o conjunto de dados MInDS-14</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">dataset </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> load_dataset(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;PolyAI/minds14&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">name</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;en-US&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">split</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;train&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Voc√™ precisa ter certeza de que a taxa de amostragem do conjunto de dados </span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># corresponde √† taxa de amostragem em que facebook/wav2vec2-base-960h foi treinado:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">dataset </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dataset.cast_column(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;audio&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, Audio(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">sampling_rate</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">speech_recognizer.feature_extractor.sampling_rate))</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Os arquivos de √°udio s√£o automaticamente carregados e reamostrados ao chamar a coluna &quot;audio&quot;.</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Extraia os arrays de forma de onda bruta (raw waveform) das primeiras 4 amostras e passe-os como uma lista para o pipeline:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">result </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> speech_recognizer(dataset[:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;audio&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">([d[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;text&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> d </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> result])</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>[&#39;I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT&#39;, </span></span>
<span class="line"><span>&quot;FONDERING HOW I&#39;D SET UP A JOIN TO HELL T WITH MY WIFE AND WHERE THE AP MIGHT BE&quot;, </span></span>
<span class="line"><span>... </span></span>
<span class="line"><span>&#39;HOW DO I FURN A JOINA COUT&#39;]</span></span></code></pre></div><p>Mais sobre datasets pode ser encontrado em <a href="https://huggingface.co/docs/datasets/quickstart" target="_blank" rel="noreferrer">Hugging Face Dataset Quick Tour</a></p><p>Para conjuntos de dados maiores onde as entradas s√£o grandes (como fala ou vis√£o), voc√™ desejar√° passar um gerador em vez de uma lista para carregar todas as entradas na mem√≥ria. D√™ uma olhada na refer√™ncia da <a href="https://huggingface.co/docs/transformers/main_classes/pipelines" target="_blank" rel="noreferrer">API do pipeline</a> para obter mais informa√ß√µes.</p><h2 id="use-outro-modelo-e-tokenizer-no-pipeline" tabindex="-1">Use outro modelo e tokenizer no pipeline <a class="header-anchor" href="#use-outro-modelo-e-tokenizer-no-pipeline" aria-label="Permalink to &quot;Use outro modelo e tokenizer no pipeline&quot;">‚Äã</a></h2><p>O <code>pipeline()</code> pode acomodar qualquer modelo (model) do <a href="https://huggingface.co/models" target="_blank" rel="noreferrer">Hub</a>, facilitando a adapta√ß√£o do <code>pipeline()</code> para outros casos de uso. Por exemplo, se voc√™ quiser um modelo capaz de lidar com texto em franc√™s, encontre o nome do modelo realizando uma busca no <a href="https://huggingface.co/models" target="_blank" rel="noreferrer">Hub</a>. Fa√ßa o filtro por task=&quot;Text classification&quot;, Language=&quot;fr&quot; e sorte=&quot;liked&quot; para encontrar um modelo apropriado. O resultado do <a href="https://huggingface.co/models?pipeline_tag=text-classification&amp;language=fr&amp;sort=likes" target="_blank" rel="noreferrer">filtro anterior</a> retorna o modelo BERT <a href="https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment" target="_blank" rel="noreferrer">bert-base-multilingual-uncased-sentiment</a> ajustado (finetuned) para <strong>an√°lise de sentimento</strong> que voc√™ pode usar para textos em franc√™s. Este modelo ajustado retorna 1 a 5 estrelas e foi treinado com reviews de produtos. Segue um exemplo de uso do modelo encontrado (BERT) para an√°lise de sentimento de um texto em ingl√™s.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> transformers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pipeline</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">classifier </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pipeline(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;sentiment-analysis&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;nlptown/bert-base-multilingual-uncased-sentiment&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(classifier(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;We are very happy to show you the Transformers library.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>[{&#39;label&#39;: &#39;5 stars&#39;, &#39;score&#39;: 0.7495927214622498}]</span></span></code></pre></div><p>√â poss√≠vel informar al√©m do modelo para o <code>pipeline</code> um tokenizer diferente. Vamos identificar qual o tokenizer associado a determinado modelo, e inform√°-lo no par√¢metro do <code>pipeline</code></p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> transformers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> AutoTokenizer, AutoModelForSequenceClassification</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> AutoModelForSequenceClassification.from_pretrained(model_name)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tokenizer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> AutoTokenizer.from_pretrained(model_name)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">classifier </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pipeline(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;sentiment-analysis&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">tokenizer</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tokenizer)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(classifier(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Nous sommes tr√®s heureux de vous pr√©senter la biblioth√®que ü§ó Transformers.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>[{&#39;label&#39;: &#39;5 stars&#39;, &#39;score&#39;: 0.7272651791572571}]</span></span></code></pre></div><p>Se n√£o conseguir encontrar um modelo para seu caso de uso, voc√™ precisar√° ajustar um modelo pr√©-treinado em seus dados. D√™ uma olhada no <a href="https://huggingface.co/docs/transformers/training" target="_blank" rel="noreferrer">tutorial de ajuste fino</a> para saber como. Por fim, depois de ajustar seu modelo pr√©-treinado, considere <a href="https://huggingface.co/docs/transformers/model_sharing" target="_blank" rel="noreferrer">compartilhar o modelo</a> com a comunidade no Hub para democratizar o aprendizado de m√°quina para todos!</p>`,25))])}const F=e(h,[["render",d]]);export{y as __pageData,F as default};
