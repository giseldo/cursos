<!DOCTYPE html>
<html lang="br" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Large Language Models: A Short Introduction | Neo</title>
    <meta name="description" content="Cursos">
    <meta name="generator" content="VitePress v1.5.0">
    <link rel="preload stylesheet" href="/cursos/assets/style.gMdbKHz8.css" as="style">
    <link rel="preload stylesheet" href="/cursos/vp-icons.css" as="style">
    
    <script type="module" src="/cursos/assets/app.ByOp5ysO.js"></script>
    <link rel="preload" href="/cursos/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/cursos/assets/chunks/framework.H8_ecXae.js">
    <link rel="modulepreload" href="/cursos/assets/chunks/theme.BHOOK2o8.js">
    <link rel="modulepreload" href="/cursos/assets/chunks/katex.cqFQqex1.js">
    <link rel="modulepreload" href="/cursos/assets/chunks/dagre-4EVJKHTY.C65Vbfr4.js">
    <link rel="modulepreload" href="/cursos/assets/chunks/c4Diagram-6F5ED5ID.BJQs--O5.js">
    <link rel="modulepreload" href="/cursos/assets/chunks/flowDiagram-7ASYPVHJ.F7yOhYd9.js">
    <link rel="modulepreload" href="/cursos/assets/chunks/erDiagram-6RL3IURR.DByvpg2E.js">
    <link rel="modulepreload" href="/cursos/assets/chunks/gitGraphDiagram-NRZ2UAAF.DYrtk-Nv.js">
    <link rel="modulepreload" href="/cursos/assets/chunks/ganttDiagram-NTVNEXSI.B5rJpRPG.js">
    <link rel="modulepreload" href="/cursos/assets/chunks/infoDiagram-A4XQUW5V.CsaOoZGh.js">
    <link rel="modulepreload" href="/cursos/assets/chunks/pieDiagram-YF2LJOPJ.DGYjBxyz.js">
    <link rel="modulepreload" href="/cursos/assets/chunks/quadrantDiagram-OS5C2QUG.DnhSBgJW.js">
    <link rel="modulepreload" href="/cursos/assets/chunks/xychartDiagram-6QU3TZC5.Bypdic37.js">
    <link rel="modulepreload" href="/cursos/assets/chunks/requirementDiagram-MIRIMTAZ.DC-rI87m.js">
    <link rel="modulepreload" href="/cursos/assets/chunks/sequenceDiagram-G6AWOVSC.Bb3QpyM5.js">
    <link rel="modulepreload" href="/cursos/assets/chunks/classDiagram-LNE6IOMH.CGAqLu52.js">
    <link rel="modulepreload" href="/cursos/assets/chunks/classDiagram-v2-MQ7JQ4JX.CGAqLu52.js">
    <link rel="modulepreload" href="/cursos/assets/chunks/stateDiagram-MAYHULR4.D7dt7WU-.js">
    <link rel="modulepreload" href="/cursos/assets/chunks/stateDiagram-v2-4JROLMXI.BIg4Nyl4.js">
    <link rel="modulepreload" href="/cursos/assets/chunks/journeyDiagram-G5WM74LC.CRUHV3Gr.js">
    <link rel="modulepreload" href="/cursos/assets/chunks/timeline-definition-U7ZMHBDA.DMBL6UF-.js">
    <link rel="modulepreload" href="/cursos/assets/chunks/mindmap-definition-GWI6TPTV.DcORkAoQ.js">
    <link rel="modulepreload" href="/cursos/assets/chunks/kanban-definition-QRCXZQQD.Cohrtqa4.js">
    <link rel="modulepreload" href="/cursos/assets/chunks/sankeyDiagram-Y46BX6SQ.D_ReM8jH.js">
    <link rel="modulepreload" href="/cursos/assets/chunks/diagram-QW4FP2JN.Bfoxb7xl.js">
    <link rel="modulepreload" href="/cursos/assets/chunks/blockDiagram-ZHA2E4KO.Brbja2xk.js">
    <link rel="modulepreload" href="/cursos/assets/chunks/architectureDiagram-UYN6MBPD.3w85NzI0.js">
    <link rel="modulepreload" href="/cursos/assets/chunks/virtual_mermaid-config.DDnGl6nM.js">
    <link rel="modulepreload" href="/cursos/assets/llm_index.md.CX8hg49b.lean.js">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-d8d3e66f><!--[--><!--]--><!--[--><span tabindex="-1" data-v-b20e631d></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-b20e631d> Skip to content </a><!--]--><!----><header class="VPNav" data-v-d8d3e66f data-v-64278d09><div class="VPNavBar" data-v-64278d09 data-v-2f9a91a8><div class="wrapper" data-v-2f9a91a8><div class="container" data-v-2f9a91a8><div class="title" data-v-2f9a91a8><div class="VPNavBarTitle has-sidebar" data-v-2f9a91a8 data-v-db1abf29><a class="title" href="/cursos/" data-v-db1abf29><!--[--><!--]--><!----><span data-v-db1abf29>Neo</span><!--[--><!--]--></a></div></div><div class="content" data-v-2f9a91a8><div class="content-body" data-v-2f9a91a8><!--[--><!--]--><div class="VPNavBarSearch search" data-v-2f9a91a8><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-2f9a91a8 data-v-94e0de4d><span id="main-nav-aria-label" class="visually-hidden" data-v-94e0de4d> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/cursos/" tabindex="0" data-v-94e0de4d data-v-b04b12fe><!--[--><span data-v-b04b12fe>Home</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/cursos/pages/sobre.html" tabindex="0" data-v-94e0de4d data-v-b04b12fe><!--[--><span data-v-b04b12fe>Sobre</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-2f9a91a8 data-v-e6826308><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-e6826308 data-v-77e720fe data-v-b5a0f3c5><span class="check" data-v-b5a0f3c5><span class="icon" data-v-b5a0f3c5><!--[--><span class="vpi-sun sun" data-v-77e720fe></span><span class="vpi-moon moon" data-v-77e720fe></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-2f9a91a8 data-v-cb473b7f data-v-e0cde419><!--[--><a class="VPSocialLink no-icon" href="https://github.com/giseldo/curdos" aria-label="github" target="_blank" rel="noopener" data-v-e0cde419 data-v-6b91c750><span class="vpi-social-github"></span></a><a class="VPSocialLink no-icon" href="https://twitter.com/giseldoneo" aria-label="twitter" target="_blank" rel="noopener" data-v-e0cde419 data-v-6b91c750><span class="vpi-social-twitter"></span></a><a class="VPSocialLink no-icon" href="https://instagram.com/neogiseldo" aria-label="instagram" target="_blank" rel="noopener" data-v-e0cde419 data-v-6b91c750><span class="vpi-social-instagram"></span></a><a class="VPSocialLink no-icon" href="https://youtube.com/giseldoneo" aria-label="youtube" target="_blank" rel="noopener" data-v-e0cde419 data-v-6b91c750><span class="vpi-social-youtube"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-2f9a91a8 data-v-c4883afd data-v-3980e32a><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-3980e32a><span class="vpi-more-horizontal icon" data-v-3980e32a></span></button><div class="menu" data-v-3980e32a><div class="VPMenu" data-v-3980e32a data-v-f8f1a359><!----><!--[--><!--[--><!----><div class="group" data-v-c4883afd><div class="item appearance" data-v-c4883afd><p class="label" data-v-c4883afd>Appearance</p><div class="appearance-action" data-v-c4883afd><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-c4883afd data-v-77e720fe data-v-b5a0f3c5><span class="check" data-v-b5a0f3c5><span class="icon" data-v-b5a0f3c5><!--[--><span class="vpi-sun sun" data-v-77e720fe></span><span class="vpi-moon moon" data-v-77e720fe></span><!--]--></span></span></button></div></div></div><div class="group" data-v-c4883afd><div class="item social-links" data-v-c4883afd><div class="VPSocialLinks social-links-list" data-v-c4883afd data-v-e0cde419><!--[--><a class="VPSocialLink no-icon" href="https://github.com/giseldo/curdos" aria-label="github" target="_blank" rel="noopener" data-v-e0cde419 data-v-6b91c750><span class="vpi-social-github"></span></a><a class="VPSocialLink no-icon" href="https://twitter.com/giseldoneo" aria-label="twitter" target="_blank" rel="noopener" data-v-e0cde419 data-v-6b91c750><span class="vpi-social-twitter"></span></a><a class="VPSocialLink no-icon" href="https://instagram.com/neogiseldo" aria-label="instagram" target="_blank" rel="noopener" data-v-e0cde419 data-v-6b91c750><span class="vpi-social-instagram"></span></a><a class="VPSocialLink no-icon" href="https://youtube.com/giseldoneo" aria-label="youtube" target="_blank" rel="noopener" data-v-e0cde419 data-v-6b91c750><span class="vpi-social-youtube"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-2f9a91a8 data-v-6c970607><span class="container" data-v-6c970607><span class="top" data-v-6c970607></span><span class="middle" data-v-6c970607></span><span class="bottom" data-v-6c970607></span></span></button></div></div></div></div><div class="divider" data-v-2f9a91a8><div class="divider-line" data-v-2f9a91a8></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-d8d3e66f data-v-f3371c70><div class="container" data-v-f3371c70><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-f3371c70><span class="vpi-align-left menu-icon" data-v-f3371c70></span><span class="menu-text" data-v-f3371c70>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-f3371c70 data-v-7bf35b01><button data-v-7bf35b01>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-d8d3e66f data-v-77192a04><div class="curtain" data-v-77192a04></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-77192a04><span class="visually-hidden" id="sidebar-aria-label" data-v-77192a04> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-8e2b8225><section class="VPSidebarItem level-0 has-active" data-v-8e2b8225 data-v-bd6104a5><div class="item" role="button" tabindex="0" data-v-bd6104a5><div class="indicator" data-v-bd6104a5></div><h2 class="text" data-v-bd6104a5>LLM (medium)</h2><!----></div><div class="items" data-v-bd6104a5><!--[--><div class="VPSidebarItem level-1 is-link" data-v-bd6104a5 data-v-bd6104a5><div class="item" data-v-bd6104a5><div class="indicator" data-v-bd6104a5></div><a class="VPLink link link" href="/cursos/llm/" data-v-bd6104a5><!--[--><p class="text" data-v-bd6104a5>Large Language Models: A Short Introduction</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-bd6104a5 data-v-bd6104a5><div class="item" data-v-bd6104a5><div class="indicator" data-v-bd6104a5></div><a class="VPLink link link" href="/cursos/llm/verygentle.html" data-v-bd6104a5><!--[--><p class="text" data-v-bd6104a5>A Very Gentle Introduction to Large Language Models without the Hype</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-d8d3e66f data-v-6a411d75><div class="VPDoc has-sidebar has-aside" data-v-6a411d75 data-v-5e576dee><!--[--><!--]--><div class="container" data-v-5e576dee><div class="aside" data-v-5e576dee><div class="aside-curtain" data-v-5e576dee></div><div class="aside-container" data-v-5e576dee><div class="aside-content" data-v-5e576dee><div class="VPDocAside" data-v-5e576dee data-v-8e8afcfb><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-8e8afcfb data-v-f2249f6d><div class="content" data-v-f2249f6d><div class="outline-marker" data-v-f2249f6d></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-f2249f6d>On this page</div><ul class="VPDocOutlineItem root" data-v-f2249f6d data-v-e7c3772a><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-8e8afcfb></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-5e576dee><div class="content-container" data-v-5e576dee><!--[--><!--]--><main class="main" data-v-5e576dee><div style="position:relative;" class="vp-doc _cursos_llm_" data-v-5e576dee><div><h1 id="large-language-models-a-short-introduction" tabindex="-1">Large Language Models: A Short Introduction <a class="header-anchor" href="#large-language-models-a-short-introduction" aria-label="Permalink to &quot;Large Language Models: A Short Introduction&quot;">​</a></h1><h2 id="sobre" tabindex="-1">sobre <a class="header-anchor" href="#sobre" aria-label="Permalink to &quot;sobre&quot;">​</a></h2><p>Este é uma tradução para portugues brasileiro, com alguns ajustes e remoção de algumas partes, da postagem publicada no <a href="https://towardsdatascience.com/large-language-models-a-short-introduction-bb8366118ad0" target="_blank" rel="noreferrer">medium</a> de autoria de Carolina Bento com o título &quot;Large Language Models: A Short Introduction&quot;.</p><p>Neste artigo, daremos uma breve olhada no que são LLMs, por que eles são uma tecnologia extremamente interessante, por que eles são importantes.</p><p>Observação: neste artigo, usaremos Large Language Model, LLM e modelo de forma intercambiável.</p><h2 id="o-que-e-um-llm" tabindex="-1">O que é um LLM <a class="header-anchor" href="#o-que-e-um-llm" aria-label="Permalink to &quot;O que é um LLM&quot;">​</a></h2><p>Um <a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" rel="noreferrer">modelo de linguagem grande</a>, normalmente chamado de LLM, é um modelo matemático que gera texto, como preencher a lacuna para a próxima palavra em uma frase.</p><iframe width="100%" height="522" src="https://www.youtube.com/embed/LPZh9BOjkQs" title="Large Language Models explained briefly" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe><p>Por exemplo, quando você o alimenta com a frase</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>The quick brown fox jumps over the lazy ____ ,</span></span></code></pre></div><p>ele não sabe exatamente que a próxima palavra é <code>dog</code>. O que o modelo produz em vez disso é uma lista de possíveis próximas palavras com suas probabilidades correspondentes de virem a seguir em uma frase que começa com essas palavras exatas.</p><p><img src="/cursos/assets/fox.vlwafcYG.png" alt=""></p><!----><p>A razão pela qual os LLMs são tão bons em prever a próxima palavra em uma frase é porque eles são treinados com uma quantidade incrivelmente grande de texto, que normalmente é raspado da Internet.</p><p>Por outro lado, se você estiver construindo um LLM que seja específico para um domínio em particular, por exemplo, você está construindo um chatbot que poderia conversar com você como se fosse um personagem nas peças de Shakespeare , a internet certamente terá muitos trechos ou até mesmo suas obras completas, mas terá uma tonelada de outros textos que não são relevantes para a tarefa em questão. Neste caso, você alimentaria o LLM no contexto de Shakespeare apenas do chatbot, ou seja, todas as suas peças e sonetos.</p><p>Embora os LLMs sejam treinados com uma quantidade gigantesca de dados, não é isso que o Large in Large Language Models representa. Além do tamanho dos dados de treinamento, a outra grande quantidade nesses modelos é o número de parâmetros que eles têm, cada um com a possibilidade de ser ajustado, ou seja, sintonizado.</p><p>O modelo estatístico mais simples é a Regressão Linear Simples , com apenas dois parâmetros, a inclinação e a interceptação. E mesmo com apenas dois parâmetros, há algumas formas diferentes que a saída do modelo pode assumir.</p><p><img src="/cursos/assets/regressao.BU19LlJt.png" alt="alt text"></p><!----><p>Como comparação, quando o GPT-3 foi lançado em 2020, ele tinha 175B parâmetros, sim, bilhões![3] Enquanto o LLaMa, o LLM de código aberto do Meta, tinha vários modelos diferentes variando de 7B a 65B parâmetros quando foi lançado em 2023 .</p><p>Todos esses bilhões de parâmetros começam com valores aleatórios, no início do processo de treinamento, e é durante a parte de retropropagação da fase de treinamento que eles são continuamente ajustados e modificados.</p><p>Semelhante a qualquer outro modelo de Machine Learning, durante a fase de treinamento, a saída do modelo é comparada com o valor real esperado para a saída, a fim de calcular o erro. Quando ainda há espaço para melhorias, a Backpropagation garante que os parâmetros do modelo sejam ajustados de forma que o modelo possa prever valores com um pouco menos de erro na próxima vez.</p><p>Mas isso é apenas o que chamamos de pré-treinamento , onde o modelo se torna proficiente em prever a próxima palavra em uma frase.</p><p>Para que o modelo tenha interações realmente boas com um humano, a ponto de você — o humano — poder fazer uma pergunta ao chatbot e sua resposta parecer estruturalmente precisa, o LLM subjacente tem que passar por uma etapa de Aprendizado por Reforço com Feedback Humano . Este é literalmente o humano no loop que é frequentemente falado no contexto de modelos de Aprendizado de Máquina.</p><p>Nessa fase, os humanos marcam as previsões que não são tão boas e, ao receber esse feedback, os parâmetros do modelo são atualizados e o modelo é treinado novamente, quantas vezes forem necessárias, para atingir o nível de qualidade de previsão desejado.</p><p>Está claro agora que esses modelos são extremamente complexos e precisam ser capazes de executar milhões, se não bilhões de cálculos. Essa computação de alta intensidade exigiu novas arquiteturas, no nível do modelo com Transformers e para computação, com GPUs .</p><p>GPU é essa classe de processadores gráficos usada em cenários quando você precisa executar um número incrivelmente grande de cálculos em um curto período de tempo, por exemplo, ao renderizar suavemente personagens em um videogame. Comparadas às CPUs tradicionais encontradas em seu laptop ou PC de torre, as GPUs têm a capacidade de executar sem esforço muitos cálculos paralelos.</p><p>O avanço para LLMs foi quando pesquisadores perceberam que GPUs também podem ser aplicadas a problemas não gráficos. Tanto Machine Learning quanto Computer Graphics dependem de álgebra linear, executando operações em matrizes, então ambos se beneficiam da capacidade de executar muitas computações paralelas.</p><p>Transformers é um novo tipo de arquitetura desenvolvida pelo Google, que faz com que cada operação feita durante o treinamento do modelo possa ser paralelizada. Por exemplo, ao prever a próxima palavra em uma frase, um modelo que usa uma arquitetura Transformer não precisa ler a frase do início ao fim, ele processa o texto inteiro ao mesmo tempo, em paralelo. Ele associa cada palavra processada a uma longa matriz de números que dão significado a essa palavra. Pensando em Álgebra Linear novamente por um segundo, em vez de processar e transformar um ponto de dados por vez, a combinação de Transformers e GPUs pode processar toneladas de pontos ao mesmo tempo, aproveitando matrizes.</p><p>Além da computação paralelizada, o que distingue os Transformers é uma operação única chamada Atenção. De uma forma muito simplista, Atenção torna possível olhar todo o contexto em torno de uma palavra, mesmo que ela ocorra várias vezes em frases diferentes como</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>At the end of the show, the singer took a bow multiple times.</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Jack wanted to go to the store to buy a new bow for target practice.</span></span></code></pre></div><p>Se nos concentrarmos na palavra <code>bow</code>, você pode ver como o contexto em que essa palavra aparece em cada frase e seu significado real são muito diferentes.</p><p>A atenção permite que o modelo refine o significado que cada palavra codifica com base no contexto ao redor delas.</p><p>Isso, mais alguns passos adicionais como treinar uma Rede Neural Feedforward , tudo feito várias vezes, faz com que o modelo gradualmente refine sua capacidade de codificar as informações corretas. Todos esses passos têm a intenção de tornar o modelo mais preciso e não misturar o significado de <code>bow</code> , o movimento e <code>bow</code> (objeto relacionado ao arco e flecha) quando ele executa uma tarefa de previsão.</p><p>Imagem e legenda retiradas do artigo referenciado em [^2].</p><p><img src="/cursos/assets/llmarch.C_qRo19l.png" alt="alt text"></p><!----><p>O desenvolvimento de Transformers e GPUs permitiu que os LLMs explodissem em uso e aplicação em comparação aos modelos de linguagem anteriores que precisavam ler uma palavra por vez. Sabendo que um modelo fica melhor quanto mais dados de qualidade ele aprende, você pode ver como processar uma palavra por vez era um grande gargalo.</p><h2 id="por-que-os-llms-sao-importantes" tabindex="-1">Por que os LLMs são importantes <a class="header-anchor" href="#por-que-os-llms-sao-importantes" aria-label="Permalink to &quot;Por que os LLMs são importantes&quot;">​</a></h2><p>Com a capacidade descrita, os LLMs podem processar enormes quantidades de exemplos de texto e então prever com alta precisão a próxima palavra em uma frase, combinado com outras estruturas poderosas de Inteligência Artificial, muitas tarefas de linguagem natural e recuperação de informações se tornaram muito mais fáceis de implementar e produtizar .</p><p>Em essência, os Grandes Modelos de Linguagem (LLMs) surgiram como sistemas de inteligência artificial de ponta que podem processar e gerar texto com comunicação coerente e generalizar múltiplas tarefas [2].</p><p>Pense em tarefas como traduzir do inglês para o espanhol, resumir um conjunto de documentos, identificar certas passagens em documentos ou ter um chatbot respondendo suas perguntas sobre um tópico específico.</p><p>Essas tarefas eram possíveis antes, mas o esforço necessário para construir um modelo era incrivelmente maior e a taxa de melhoria desses modelos era muito mais lenta devido a gargalos tecnológicos. Os LLMs chegaram e turbinaram todas essas tarefas e aplicações.</p><p>Você provavelmente já interagiu ou viu alguém interagindo diretamente com produtos que usam LLMs em sua essência.</p><p>Esses produtos são muito mais do que um simples LLM que prevê com precisão a próxima palavra em uma frase. Eles alavancam LLMs e outras técnicas e estruturas de Machine Learning para entender o que você está perguntando, pesquisar todas as informações contextuais que eles viram até agora e apresentar a você uma resposta humana e, na maioria das vezes, coerente. Ou pelo menos alguns fornecem orientação sobre o que procurar em seguida.</p><p>Existem vários produtos de Inteligência Artificial (IA) que alavancam LLMs, desde o Meta AI do Facebook , o Gemini do Google, o ChatGPT da Open AI , que toma emprestado seu nome da tecnologia Generative Pre-trained Transformer, o CoPilot da Microsoft , entre muitos, muitos outros, abrangendo uma ampla gama de tarefas para ajudar você.</p><h2 id="conclusao" tabindex="-1">Conclusão <a class="header-anchor" href="#conclusao" aria-label="Permalink to &quot;Conclusão&quot;">​</a></h2><p>Os LMMs são, sem dúvida, uma área de pesquisa emergente que vem evoluindo em um ritmo extremamente rápido, como você pode ver na linha do tempo abaixo.</p><p>Imagem e legenda retiradas do artigo referenciado em [^1]</p><p><img src="/cursos/assets/linhadotempo.b4jBv9IK.png" alt="alt text"></p><!----><p>Estamos apenas nos primeiros dias da produtização, ou aplicação de produtos. Mais e mais empresas estão aplicando LLMs em suas áreas de domínio, a fim de simplificar tarefas que levariam vários anos e uma quantidade incrível de fundos para pesquisar, desenvolver e levar ao mercado.</p><p>Quando aplicados de forma ética e consciente do consumidor, os LLMs e produtos que têm LLMs em seu núcleo fornecem uma grande oportunidade para todos. Para pesquisadores, é um campo de ponta com uma riqueza de problemas teóricos e práticos para desembaraçar.</p><p>Por exemplo, em Genômica, gLMs ou Modelos de Linguagem Genômica, ou seja, Grandes Modelos de Linguagem treinados em sequências de DNA, são usados ​​para acelerar nossa compreensão geral dos genomas e como o DNA funciona e interage com outras funções[4]. Essas são grandes questões para as quais os cientistas não têm respostas definitivas, mas os LLMs estão provando ser uma ferramenta que pode ajudá-los a progredir em uma escala muito maior e iterar suas descobertas muito mais rápido. Para fazer um progresso constante na ciência, ciclos de feedback rápidos são cruciais.</p><h2 id="referencias" tabindex="-1">Referências <a class="header-anchor" href="#referencias" aria-label="Permalink to &quot;Referências&quot;">​</a></h2><p>[^1]:Uma visão geral abrangente de grandes modelos de linguagem . 2024. Humza Naveed e Asad Ullah Khan e Shi Qiu e Muhammad Saqib e Saeed Anwar e Muhammad Usman e Naveed Akhtar e Nick Barnes e Ajmal Mian.</p><p>[3] Modelos de linguagem são aprendizes de poucas tentativas . 2020. Tom B. Brown e Benjamin Mann e Nick Ryder e Melanie Subbiah e Jared Kaplan e Prafulla Dhariwal e Arvind Neelakantan e Pranav Shyam e Girish Sastry e Amanda Askell e Sandhini Agarwal e Ariel Herbert-Voss e Gretchen Krueger e Tom Henighan e Rewon Child e Aditya Ramesh e Daniel M. Ziegler e Jeffrey Wu e Clemens Winter e Christopher Hesse e Mark Chen e Eric Sigler e Mateusz Litwin e Scott Gray e Benjamin Chess e Jack Clark e Christopher Berner e Sam McCandlish e Alec Radford e Ilya Sutskever e Dario Amodei</p><p>[4] Modelos de linguagem genômica: oportunidades e desafios . 2024. Gonzalo Benegas e Chengzhong Ye e Carlos Albors e Jianan Canal Li e Yun S. Song.</p><p>[^2]: Bento, Carolina. &quot;Large Language Models: A Short Introduction.&quot; Medium, Towards Data Science, 2023.</p></div></div></main><footer class="VPDocFooter" data-v-5e576dee data-v-7ae10264><!--[--><!--]--><!----><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-7ae10264><span class="visually-hidden" id="doc-footer-aria-label" data-v-7ae10264>Pager</span><div class="pager" data-v-7ae10264><!----></div><div class="pager" data-v-7ae10264><a class="VPLink link pager-link next" href="/cursos/llm/verygentle.html" data-v-7ae10264><!--[--><span class="desc" data-v-7ae10264>Next page</span><span class="title" data-v-7ae10264>A Very Gentle Introduction to Large Language Models without the Hype</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-d8d3e66f data-v-bc8227f9><div class="container" data-v-bc8227f9><p class="message" data-v-bc8227f9>Todos os direitos reservados.</p><p class="copyright" data-v-bc8227f9>© 2025 Giseldo Neo</p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"am_cap2.md\":\"x3NvxdqF\",\"am_cap3.md\":\"BtGjcjWf\",\"am_index.md\":\"DigP7ArE\",\"articles_index.md\":\"C7Mt2id-\",\"chatbot_1-como-criar.md\":\"CkqO3fMZ\",\"chatbot_index.md\":\"OUy16CBP\",\"chatbotbook_10_criando_chatbots_com_llms_através_da_engenharia_de_prompts.md\":\"CL4q_EJN\",\"chatbotbook_11_expressões_regulares.md\":\"DaFPaOL-\",\"chatbotbook_12_usando_o_gpt2.md\":\"D-H33u5W\",\"chatbotbook_13_crie_um_gpt_do_zero.md\":\"3DMXsh5-\",\"chatbotbook_1_chatbots_definições_e_contexto.md\":\"DkTi6OYt\",\"chatbotbook_2_eliza_explicado.md\":\"ByWPpVoi\",\"chatbotbook_3_artificial_intelligence_markup_language.md\":\"DQMZ0nFt\",\"chatbotbook_4_processamento_de_linguagem_natural.md\":\"WY2sGEeX\",\"chatbotbook_5_intenção_em_chatbots_chap_intents_.md\":\"B0M7Zsuq\",\"chatbotbook_6_llm.md\":\"7ifnhO8p\",\"chatbotbook_7_retrieval_augmented_generation.md\":\"BrDHPyOZ\",\"chatbotbook_8_chatbot_eliza_em_python.md\":\"bTenI0I5\",\"chatbotbook_9_usando_chatgpt_com_langchain.md\":\"D4egKQI_\",\"chatbotbook_index.md\":\"B7Hsp0JO\",\"estatistica_index.md\":\"BjUwvP_I\",\"estatistica_pag2.md\":\"rgL7p3Rm\",\"index.md\":\"BCGw6IZ2\",\"llm_index.md\":\"CX8hg49b\",\"llm_verygentle.md\":\"DuzCTuRI\",\"nlp_index.md\":\"DEgCtiV1\",\"pages_sobre.md\":\"DSMqWM9v\",\"pln_1-introducao.md\":\"CJZkSIqo\",\"pln_2-transformers.md\":\"BKFuHYHT\",\"pln_index.md\":\"Bhk6lKr7\",\"pln_parte-2.md\":\"DbrFs6t7\",\"regressao_1-intro.md\":\"D69i_U4K\",\"regressao_2-video.md\":\"Cb9Xx3Xk\",\"regressao_3-exercicios.md\":\"Cipf-cx8\",\"regressao_index.md\":\"DBkEe3hL\",\"transformers_index.md\":\"CL2o6vqW\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"br\",\"dir\":\"ltr\",\"title\":\"Neo\",\"description\":\"Cursos\",\"base\":\"/cursos/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"outline\":{\"level\":[2,3]},\"nav\":[{\"text\":\"Home\",\"link\":\"/\"},{\"text\":\"Sobre\",\"link\":\"/pages/sobre\"}],\"sidebar\":{\"/chatbotbook/\":[{\"text\":\"Chatbotbook\",\"items\":[{\"text\":\"Index\",\"link\":\"/chatbotbook/\"},{\"text\":\"Definições e contexto\",\"link\":\"/chatbotbook/1_chatbots_definições_e_contexto\"},{\"text\":\"Eliza Explicado\",\"link\":\"/chatbotbook/2_eliza_explicado\"},{\"text\":\"Artificial Intelligence Markup Language\",\"link\":\"/chatbotbook/3_artificial_intelligence_markup_language\"},{\"text\":\"Processamento de Linguagem Natural\",\"link\":\"/chatbotbook/4_processamento_de_linguagem_natural\"},{\"text\":\"Intenção em chatbots\",\"link\":\"/chatbotbook/5_intenção_em_chatbots_chap_intents_\"},{\"text\":\"Large Language Models\",\"link\":\"/chatbotbook/6_llm\"},{\"text\":\"Retrieval Augmented Generation\",\"link\":\"/chatbotbook/7_retrieval_augmented_generation\"},{\"text\":\"Chatbot Eliza em Python\",\"link\":\"/chatbotbook/8_chatbot_eliza_em_python\"},{\"text\":\"Usando Chatgpt com Langchain\",\"link\":\"/chatbotbook/9_usando_chatgpt_com_langchain\"},{\"text\":\"Criando Chatbots com LLMs através da Engenharia de Prompts\",\"link\":\"/chatbotbook/10__criando_chatbots_com_llms_através_da_engenharia_de_prompts\"},{\"text\":\"Expressões Regulares\",\"link\":\"/chatbotbook/11_expresões_regulares\"},{\"text\":\"Usando o Gpt2\",\"link\":\"/chatbotbook/12_usando_o_gpt2\"}]}],\"/estatistica/\":[{\"text\":\"Estatística\",\"items\":[{\"text\":\"Pag 1\",\"link\":\"/estatistica/\"},{\"text\":\"Pag 2\",\"link\":\"/estatistica/pag2\"}]}],\"/am/\":[{\"text\":\"AM\",\"items\":[{\"text\":\"Introdução\",\"link\":\"/am/\"},{\"text\":\"Pag 2\",\"link\":\"/am/cap2\"},{\"text\":\"Pag 3\",\"link\":\"/am/cap3\"},{\"text\":\"Pag 4\",\"link\":\"/am/cap4\"},{\"text\":\"Pag 4\",\"link\":\"/am/cap5\"}]}],\"/pln/\":[{\"text\":\"Processamento de linguagem natural\",\"items\":[{\"text\":\"Sobre\",\"link\":\"/pln/\"},{\"text\":\"Introdução\",\"link\":\"/pln/1-introducao\"},{\"text\":\"Transformers\",\"link\":\"/pln/2-transformers\"}]}],\"/nlp/\":[{\"text\":\"NLP\",\"items\":[{\"text\":\"Introdução\",\"link\":\"/nlp/\"}]}],\"/llm/\":[{\"text\":\"LLM (medium)\",\"items\":[{\"text\":\"Large Language Models: A Short Introduction\",\"link\":\"/llm/\"},{\"text\":\"A Very Gentle Introduction to Large Language Models without the Hype\",\"link\":\"/llm/verygentle\"}]}],\"/transformers/\":[{\"text\":\"Transformers\",\"items\":[{\"text\":\"Introdução\",\"link\":\"/transformers/\"}]}],\"/chatbot/\":[{\"text\":\"Chatbot\",\"items\":[{\"text\":\"Sobre\",\"link\":\"/chatbot/\"},{\"text\":\"Como criar um chatbot\",\"link\":\"/chatbot/1-como-criar\"}]}],\"/regressao/\":[{\"text\":\"Regressao Linear\",\"items\":[{\"text\":\"Sobre\",\"link\":\"/regressao/\"},{\"text\":\"Introdução\",\"link\":\"/regressao/1-intro\"},{\"text\":\"Vídeo\",\"link\":\"/regressao/2-video\"},{\"text\":\"Exercício\",\"link\":\"/regressao/3-exercicios\"}]}]},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/giseldo/curdos\"},{\"icon\":\"twitter\",\"link\":\"https://twitter.com/giseldoneo\"},{\"icon\":\"instagram\",\"link\":\"https://instagram.com/neogiseldo\"},{\"icon\":\"youtube\",\"link\":\"https://youtube.com/giseldoneo\"}],\"footer\":{\"message\":\"Todos os direitos reservados.\",\"copyright\":\"© 2025 Giseldo Neo\"},\"search\":{\"provider\":\"local\"}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>