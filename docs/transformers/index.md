# Transformers Quickstart

Essa √© uma tradu√ßao (com pequenos ajustes) do material [transformers quicktour](https://huggingface.co/docs/transformers/quicktour) do Hugging Face.

## Introdu√ß√£o

Este post mostrar√° como usar o ```pipeline()``` para infer√™ncia, como carregar um modelo pr√©-treinado, um pr√©-processador e treinar um modelo com **PyTorch**.

Antes de come√ßar, certifique-se de ter todas as bibliotecas necess√°rias instaladas:

```bash
pip install transformers datasets evaluate accelerate torch
```

O ```pipeline()``` √© a maneira mais f√°cil e r√°pida de usar um modelo pr√©-treinado para infer√™ncia.
Voc√™ pode usar o ```pipeline()``` pronto para uso para muitas Tarefas (Tabela 1) em diferentes modalidades, algumas das quais s√£o mostradas na tabela abaixo:

<center>Tabela 1 - Tarefas poss√≠veis com o pipeline do Transformers.</center>

|Descri√ßao da Tarefa|Identificador do Pipeline|
|----|----|
|Classifica√ß√£o de texto|pipeline(task=‚Äúsentiment-analysis‚Äù)|
|Gera√ß√£o de Texto|pipeline(task=‚Äútext-generation‚Äù)|
|reconhecimento autom√°tico de fala|pipeline(task=‚Äúautomatic-speech-recognition‚Äù)|

## Exemplo an√°lise de sentimento

Comece criando uma inst√¢ncia de ```pipeline()``` e especificando uma tarefa para a qual voc√™ deseja us√°-lo.
O ```pipeline()``` baixa e armazena em cache um modelo pr√©-treinado padr√£o e um tokenizador para an√°lise de sentimento.
Agora voc√™ pode usar o classificador no seu texto de destino.
Neste guia, voc√™ usar√° o ```pipeline()``` para an√°lise de sentimentos como um exemplo:

```python
from transformers import pipeline
classifier = pipeline("sentiment-analysis")
classifier("We are very happy to show you the Transformers library.")
```

```
[{'label': 'POSITIVE', 'score': 0.9997795224189758}]
```

Se voc√™ tiver mais de uma entrada, passe suas entradas como uma lista para o ```pipeline()``` para retornar uma lista de dicion√°rios:

```python
from transformers import pipeline
classifier = pipeline("sentiment-analysis")
results = classifier(["We are very happy to show you the Transformers library.", "We hope you don't hate it."])
for result in results:
    print(f"label: {result['label']}, with score: {round(result['score'], 4)}")
```

```
    label: POSITIVE, with score: 0.9998
    label: NEGATIVE, with score: 0.5309
```

## Exemplo reconhecimento autom√°tico de fala

O ```pipeline()``` tamb√©m pode iterar um conjunto de dados inteiro para qualquer tarefa que voc√™ desejar. Para este exemplo, vamos escolher o pipeline **reconhecimento autom√°tico de fala** utilizando o modelo [facebook/wav2vec2-base-960h](https://huggingface.co/facebook/wav2vec2-base-960h)

Instale a depend√™ncia:

```bash
pip install librosa soundfile 
```

Carregue um conjunto de dados de √°udio que voc√™ gostaria de iterar.
Por exemplo, carregue o conjunto de dados [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14)

```python
import torch
from transformers import pipeline
from datasets import load_dataset, Audio

speech_recognizer = pipeline("automatic-speech-recognition", model="facebook/wav2vec2-base-960h")

# carregando o conjunto de dados MInDS-14
dataset = load_dataset("PolyAI/minds14", name="en-US", split="train")

# Voc√™ precisa ter certeza de que a taxa de amostragem do conjunto de dados 
# corresponde √† taxa de amostragem em que facebook/wav2vec2-base-960h foi treinado:
dataset = dataset.cast_column("audio", Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))

# Os arquivos de √°udio s√£o automaticamente carregados e reamostrados ao chamar a coluna "audio".
# Extraia os arrays de forma de onda bruta (raw waveform) das primeiras 4 amostras e passe-os como uma lista para o pipeline:
result = speech_recognizer(dataset[:4]["audio"])
print([d["text"] for d in result])
```

```
['I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT', 
"FONDERING HOW I'D SET UP A JOIN TO HELL T WITH MY WIFE AND WHERE THE AP MIGHT BE", 
... 
'HOW DO I FURN A JOINA COUT']
```

Mais sobre datasets pode ser encontrado em [Hugging Face Dataset Quick Tour](https://huggingface.co/docs/datasets/quickstart)

Para conjuntos de dados maiores onde as entradas s√£o grandes (como fala ou vis√£o), voc√™ desejar√° passar um gerador em vez de uma lista para carregar todas as entradas na mem√≥ria. D√™ uma olhada na refer√™ncia da [API do pipeline](https://huggingface.co/docs/transformers/main_classes/pipelines) para obter mais informa√ß√µes.

## Use outro modelo e tokenizer no pipeline

O ```pipeline()``` pode acomodar qualquer modelo (model) do [Hub](https://huggingface.co/models), facilitando a adapta√ß√£o do ```pipeline()``` para outros casos de uso. Por exemplo, se voc√™ quiser um modelo capaz de lidar com texto em franc√™s, encontre o nome do modelo realizando uma busca no [Hub](https://huggingface.co/models). Fa√ßa o filtro por task="Text classification", Language="fr" e sorte="liked" para encontrar um modelo apropriado. O resultado do [filtro anterior](https://huggingface.co/models?pipeline_tag=text-classification&language=fr&sort=likes) retorna o modelo BERT [bert-base-multilingual-uncased-sentiment](https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment) ajustado (finetuned) para **an√°lise de sentimento** que voc√™ pode usar para textos em franc√™s. Este modelo ajustado retorna 1 a 5 estrelas e foi treinado com reviews de produtos. Segue um exemplo de uso do modelo encontrado (BERT) para an√°lise de sentimento de um texto em ingl√™s.

```python
from transformers import pipeline
classifier = pipeline("sentiment-analysis", model='nlptown/bert-base-multilingual-uncased-sentiment')
print(classifier("We are very happy to show you the Transformers library."))
```

```
[{'label': '5 stars', 'score': 0.7495927214622498}]
```

√â poss√≠vel informar al√©m do modelo para o ```pipeline``` um tokenizer diferente. Vamos identificar qual o tokenizer associado a determinado modelo, e inform√°-lo no par√¢metro do ```pipeline```

```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)

classifier = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)

print(classifier("Nous sommes tr√®s heureux de vous pr√©senter la biblioth√®que ü§ó Transformers."))
```

```
[{'label': '5 stars', 'score': 0.7272651791572571}]
```

Se n√£o conseguir encontrar um modelo para seu caso de uso, voc√™ precisar√° ajustar um modelo pr√©-treinado em seus dados. D√™ uma olhada no [tutorial de ajuste fino](https://huggingface.co/docs/transformers/training) para saber como. Por fim, depois de ajustar seu modelo pr√©-treinado, considere [compartilhar o modelo](https://huggingface.co/docs/transformers/model_sharing) com a comunidade no Hub para democratizar o aprendizado de m√°quina para todos!
